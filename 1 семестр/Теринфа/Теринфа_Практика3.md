Наверное, 3. Какая разница

Код Хэмминга и дистанция Хэмминга
Дистанция Хэмминга между двумя сообщениями одинаковой длины - количество различающихся битов 

Сделать так, чтобы дистанция между двумя соседними была не менее 3. 1 задание - любой длины, 2 - минимально:
A  1 1 1 1 1
B  0 0 0 1 1
C  1 1 0 0 0
D  0 0 1 0 0
В этой ситуации 5 число добавить невозможно 
Количество бит растет очень быстро с добавлением новых чисел или с увеличением дистанции. Поэтому метод и не используют на практике 

Формула Хартли 
Если есть N событий, то i = log2(N) - количество бит полученной информации 
16 пассажирских вагонов, он в 5 - мы получили 4 бита информации
P = k/N - вероятность 
при 20 юношах и 10 девушках:
Р(д) = 1/3 - 1.58 бит
Р(ю) = 2/3 - 0.58 бит
i = log2(1/Р) 
Значит чем меньше событий, тем больше информации

Задача:
5, 4, 3 - оценка ученика
Р(5) = 0.6
Р(4) = 0.3
Р(3) = 0.1 
Сколько информации он получил в каждом случае?
i (5) = 0.74
i (4) = 1.74
i (3) = 3.32

Задача:
Черные и белые шары, черных 18, информации в сообщение, что вынули белый шар = 2 бита. Сколько всего шаров?
log(2)1/Р = 2
1/P = 4  P = 0.25
кол-во белых - Б
N = Б + 18 
4 = (Б+ 18) / Б => Б = 6

Задача:
Есть группа людей, каждый знает какой-то язык - Н, Ф, А
Не А = 30
i(A) = 1 + log(2)3
i(Ф) = 2
Н = ? = 21

Новая формула - формула Шенона для одинарного события - гугли 
Ее обязательное условие - сумма вероятностей (Р) должна быть 1 

Будет дана таблица вероятности попадания букв русского алфавита. 
Надо будет выбрать набор определенных символов. 
